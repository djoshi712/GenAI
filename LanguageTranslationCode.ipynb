{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vknlscMTEJx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece --quiet\n",
        "!pip install sacrebleu --quiet\n",
        "!pip install torchdata --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRaB9pelTO_2",
        "outputId": "5be345de-d130-4c35-bba6-2d90fca15891"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y torch torchvision torchdata torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgRmx_2Ayixu",
        "outputId": "d0040656-61f4-45fe-961e-dac767eb5540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# print(torch.__version__)\n",
        "# print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "aHHuKbD-LO1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==1.13.1+cu117 torchtext==0.14.1 torchdata -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "metadata": {
        "id": "caXIKaNeL7b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path= '/content/drive/MyDrive/Projects/Train'\n",
        "valid_path= '/content/drive/MyDrive/Projects/Valid'"
      ],
      "metadata": {
        "id": "b_nJXHsQQI6d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import sacrebleu\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RNl3Q8XTPAZ",
        "outputId": "0ba39f7b-d06f-4987-8b4c-0b453fc40f20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = \"de\"\n",
        "TRG = \"en\"\n",
        "BOS, EOS, PAD = 1, 2, 3\n",
        "batch_size = 128\n",
        "max_seq_len = 50\n",
        "\n",
        "en_vocab_size = 8200\n",
        "de_vocab_size = 10000\n",
        "vocab_sizes = {\"en\": en_vocab_size, \"de\": de_vocab_size}"
      ],
      "metadata": {
        "id": "o6rXTHr4UzHC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MDyAHYsVShbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "class SentencePieceProcessor:\n",
        "    def __init__(self, src_language, trg_language, de_vocab_size=10000, en_vocab_size=8200):\n",
        "        self.SRC = src_language\n",
        "        self.TRG = trg_language\n",
        "        self.de_vocab_size = de_vocab_size\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.vocab_sizes = {\"en\": self.en_vocab_size, \"de\": self.de_vocab_size}\n",
        "        self.tokenizers = {}\n",
        "        self.detokenizers = {}\n",
        "\n",
        "    def prepare_data(self, train_src_path, train_trg_path, valid_src_path, valid_trg_path):\n",
        "\n",
        "        # Create cleaned text files for training\n",
        "        with open(train_src_path, \"r\") as train_src, open(train_trg_path, \"r\") as train_trg:\n",
        "            with open(\"Multi30k_train_de_text.txt\", \"w\") as out_de, open(\"Multi30k_train_en_text.txt\", \"w\") as out_en:\n",
        "                for de_line, en_line in zip(train_src, train_trg):\n",
        "                    out_de.write(de_line.strip() + '\\n')\n",
        "                    out_en.write(en_line.strip() + '\\n')\n",
        "\n",
        "        # Create cleaned text files for validation\n",
        "        with open(valid_src_path, \"r\") as valid_src, open(valid_trg_path, \"r\") as valid_trg:\n",
        "            with open(\"Multi30k_valid_de_text.txt\", \"w\") as out_de, open(\"Multi30k_valid_en_text.txt\", \"w\") as out_en:\n",
        "                for de_line, en_line in zip(valid_src, valid_trg):\n",
        "                    out_de.write(de_line.strip() + '\\n')\n",
        "                    out_en.write(en_line.strip() + '\\n')\n",
        "\n",
        "    def train_sentencepiece(self):\n",
        "        \"\"\"\n",
        "        Trains SentencePiece models for both source (de) and target (en) languages using the prepared training text.\n",
        "        \"\"\"\n",
        "        # Train SentencePiece for German (de)\n",
        "        spm.SentencePieceTrainer.train(f'--input=Multi30k_train_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size={self.de_vocab_size}')\n",
        "\n",
        "        # Train SentencePiece for English (en)\n",
        "        spm.SentencePieceTrainer.train(f'--input=Multi30k_train_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size={self.en_vocab_size}')\n",
        "\n",
        "        # Load trained SentencePiece models\n",
        "        de_sp = spm.SentencePieceProcessor()\n",
        "        de_sp.load('Multi30k_de.model')\n",
        "        en_sp = spm.SentencePieceProcessor()\n",
        "        en_sp.load('Multi30k_en.model')\n",
        "\n",
        "        # Set tokenizers and detokenizers\n",
        "        self.tokenizers = {\"de\": de_sp, \"en\": en_sp}\n",
        "        self.detokenizers = {\"de\": de_sp.decode_ids, \"en\": en_sp.decode_ids}\n",
        "\n",
        "    def get_special_symbols_indexes(self):\n",
        "        \"\"\"\n",
        "        Returns a dictionary of special symbol indexes (e.g., UNK, BOS, EOS, PAD).\n",
        "        \"\"\"\n",
        "        return {\"UNK\": 0, \"BOS\": 1, \"EOS\": 2, \"PAD\": 3}\n"
      ],
      "metadata": {
        "id": "A2R0wy78TPDX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the class without a main function\n",
        "# Initialize the SentencePieceProcessor\n",
        "\n",
        "train_src_path='/content/drive/MyDrive/Projects/Train/train.de'\n",
        "train_trg_path='/content/drive/MyDrive/Projects/Train/train.en'\n",
        "valid_src_path='/content/drive/MyDrive/Projects/Valid/val.de'\n",
        "valid_trg_path='/content/drive/MyDrive/Projects/Valid/val.en'\n",
        "\n",
        "src_language = \"de\"\n",
        "trg_language = \"en\"\n",
        "\n",
        "sp_processor = SentencePieceProcessor(src_language, trg_language)\n",
        "\n",
        "# Prepare data for training and validation\n",
        "sp_processor.prepare_data(train_src_path, train_trg_path, valid_src_path, valid_trg_path)\n",
        "\n",
        "# Train SentencePiece tokenizers\n",
        "sp_processor.train_sentencepiece()\n",
        "\n",
        "# Get special symbols (e.g., UNK, BOS, EOS, PAD)\n",
        "special_symbols = sp_processor.get_special_symbols_indexes()\n",
        "\n",
        "# Example: Tokenize a sentence using the trained tokenizer\n",
        "sentence = \"Das ist ein Beispiel.\"\n",
        "tokenized_sentence = sp_processor.tokenizers[\"de\"].encode_as_ids(sentence)\n",
        "print(\"Tokenized sentence:\", tokenized_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT2n-gol2SzR",
        "outputId": "5ef4605a-a502-4780-ef64-ff322be37561"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentence: [251, 57, 13, 669, 1359, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints tokenized examples of the first few sentence pairs.\n",
        "with open(\"Multi30k_en_text.txt\", \"r\") as f_en, open(\"Multi30k_de_text.txt\", \"r\") as f_de:\n",
        "  print(\"Tokenized sentence pairs:\")\n",
        "  for _ in range(5):\n",
        "      en_line = f_en.readline().strip()\n",
        "      de_line = f_de.readline().strip()\n",
        "\n",
        "      # Tokenize each line using SentencePiece tokenizer\n",
        "      en_pieces = sp_processor.tokenizers[\"en\"].encode_as_pieces(en_line)\n",
        "      en_tokens = sp_processor.tokenizers[\"en\"].encode_as_ids(en_line)\n",
        "\n",
        "      de_pieces = sp_processor.tokenizers[\"de\"].encode_as_pieces(de_line)\n",
        "      de_tokens = sp_processor.tokenizers[\"de\"].encode_as_ids(de_line)\n",
        "      print(f\"English: {en_line}\")\n",
        "      print(f\"Tokenized English: {en_pieces}\")\n",
        "      print(f\"Token to id's English: {en_tokens}\")\n",
        "      print(f\"German: {de_line}\")\n",
        "      print(f\"Tokenized German: {de_pieces}\")\n",
        "      print(f\"Token to id's German: {de_tokens}\")\n",
        "\n",
        "      print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjpnTvnSSsRL",
        "outputId": "d33446ba-f3dc-4131-bbe3-7f0fb5e0c8cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentence pairs:\n",
            "English: Two young, White males are outside near many bushes.\n",
            "Tokenized English: ['▁Two', '▁young', ',', '▁White', '▁males', '▁are', '▁outside', '▁near', '▁many', '▁bushes', '.']\n",
            "Token to id's English: [22, 28, 18, 1317, 936, 20, 62, 89, 404, 1519, 5]\n",
            "German: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
            "Tokenized German: ['▁Zwei', '▁junge', '▁weiße', '▁Männer', '▁sind', '▁im', '▁Freien', '▁in', '▁der', '▁Nähe', '▁viele', 'r', '▁Büsche', '.']\n",
            "Token to id's German: [25, 93, 137, 38, 99, 27, 107, 8, 18, 126, 280, 33, 4184, 4]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "English: Several men in hard hats are operating a giant pulley system.\n",
            "Tokenized English: ['▁Se', 'veral', '▁men', '▁in', '▁hard', '▁hats', '▁are', '▁operating', '▁a', '▁g', 'iant', '▁pulley', '▁system', '.']\n",
            "Token to id's English: [309, 197, 39, 7, 356, 339, 20, 1361, 4, 394, 1597, 4134, 3127, 5]\n",
            "German: Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
            "Tokenized German: ['▁Mehrer', 'e', '▁Männer', '▁mit', '▁Schutzhelmen', '▁bedienen', '▁ein', '▁An', 'triebs', 'rad', 'system', '.']\n",
            "Token to id's German: [95, 48, 38, 9, 979, 2754, 13, 544, 7776, 1149, 6166, 4]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "English: A little girl climbing into a wooden playhouse.\n",
            "Tokenized English: ['▁A', '▁little', '▁girl', '▁climbing', '▁in', 'to', '▁a', '▁wooden', '▁playhouse', '.']\n",
            "Token to id's English: [6, 64, 36, 256, 7, 95, 4, 271, 4781, 5]\n",
            "German: Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
            "Tokenized German: ['▁Ein', '▁kleines', '▁Mädchen', '▁klettert', '▁in', '▁ein', '▁Spiel', 'haus', '▁aus', '▁Holz', '.']\n",
            "Token to id's German: [6, 80, 31, 234, 8, 13, 299, 1471, 61, 314, 4]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "English: A man in a blue shirt is standing on a ladder cleaning a window.\n",
            "Tokenized English: ['▁A', '▁man', '▁in', '▁a', '▁blue', '▁shirt', '▁is', '▁standing', '▁on', '▁a', '▁ladder', '▁clean', 'ing', '▁a', '▁window', '.']\n",
            "Token to id's English: [6, 11, 7, 4, 33, 27, 10, 40, 9, 4, 644, 435, 16, 4, 262, 5]\n",
            "German: Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
            "Tokenized German: ['▁Ein', '▁Mann', '▁in', '▁eine', 'm', '▁blauen', '▁Hemd', '▁steht', '▁auf', '▁einer', '▁Leiter', '▁und', '▁putzt', '▁ein', '▁Fenster', '.']\n",
            "Token to id's German: [6, 14, 8, 5, 7, 55, 50, 37, 12, 15, 591, 11, 787, 13, 244, 4]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "English: Two men are at the stove preparing food.\n",
            "Tokenized English: ['▁Two', '▁men', '▁are', '▁at', '▁the', '▁stove', '▁preparing', '▁food', '.']\n",
            "Token to id's English: [22, 39, 20, 23, 8, 1319, 417, 146, 5]\n",
            "German: Zwei Männer stehen am Herd und bereiten Essen zu.\n",
            "Tokenized German: ['▁Zwei', '▁Männer', '▁stehen', '▁am', '▁Herd', '▁und', '▁bereite', 'n', '▁Essen', '▁zu', '.']\n",
            "Token to id's German: [25, 38, 64, 67, 1329, 11, 780, 17, 187, 35, 4]\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "class DataPreparation:\n",
        "    def __init__(self, train_src_path, train_trg_path, valid_src_path, valid_trg_path, tokenizers, special_symbols, max_seq_len=50):\n",
        "        self.SRC = \"de\"  # German source language\n",
        "        self.TRG = \"en\"  # English target language\n",
        "        self.train_src_path = train_src_path\n",
        "        self.train_trg_path = train_trg_path\n",
        "        self.valid_src_path = valid_src_path\n",
        "        self.valid_trg_path = valid_trg_path\n",
        "        self.tokenizers = tokenizers  # Tokenizers for \"de\" and \"en\"\n",
        "        self.special_symbols = special_symbols  # Special symbols indexes (e.g., BOS, EOS, PAD)\n",
        "        self.max_seq_len = max_seq_len  # Max sequence length for tokenization\n",
        "\n",
        "        # Load and prepare datasets\n",
        "        self.train_set = self._prepare_set(self.train_src_path, self.train_trg_path)\n",
        "        self.valid_set = self._prepare_set(self.valid_src_path, self.valid_trg_path)\n",
        "\n",
        "    def _prepare_set(self, src_file_path, trg_file_path):\n",
        "        \"\"\"Reads sentences from source and target files and pairs them.\"\"\"\n",
        "        if not os.path.exists(src_file_path) or not os.path.exists(trg_file_path):\n",
        "            raise FileNotFoundError(\"Source or target file not found.\")\n",
        "\n",
        "        # Read source and target files\n",
        "        with open(src_file_path, 'r', encoding='utf-8') as src_file, \\\n",
        "             open(trg_file_path, 'r', encoding='utf-8') as trg_file:\n",
        "            src_lines = src_file.readlines()\n",
        "            trg_lines = trg_file.readlines()\n",
        "\n",
        "        # Ensure both files have the same number of lines\n",
        "        if len(src_lines) != len(trg_lines):\n",
        "            raise ValueError(\"Source and target files have different line counts.\")\n",
        "\n",
        "        # Pair sentences and remove trailing newlines\n",
        "        data_set = [(src.strip(), trg.strip()) for src, trg in zip(src_lines, trg_lines) if src.strip() and trg.strip()]\n",
        "        return data_set\n",
        "\n",
        "    def tokenize_dataset(self, dataset):\n",
        "        \"\"\"\n",
        "        Tokenizes the dataset using the SentencePiece tokenizers.\n",
        "        Each sequence is wrapped with BOS and EOS tokens and truncated to max_seq_len.\n",
        "        \"\"\"\n",
        "        BOS = self.special_symbols[\"BOS\"]\n",
        "        EOS = self.special_symbols[\"EOS\"]\n",
        "\n",
        "        tokenized_dataset = []\n",
        "        for src_text, trg_text in dataset:\n",
        "            src_tokens = [BOS] + self.tokenizers[\"de\"].encode_as_ids(src_text)[:self.max_seq_len-2] + [EOS]\n",
        "            trg_tokens = [BOS] + self.tokenizers[\"en\"].encode_as_ids(trg_text)[:self.max_seq_len-2] + [EOS]\n",
        "            tokenized_dataset.append((torch.tensor(src_tokens), torch.tensor(trg_tokens)))\n",
        "\n",
        "        return tokenized_dataset\n",
        "\n",
        "    def print_data_info(self):\n",
        "        \"\"\"Prints dataset information and a few examples.\"\"\"\n",
        "        print(\"Number of training examples:\", len(self.train_set))\n",
        "        print(\"Number of validation examples:\", len(self.valid_set))\n",
        "\n",
        "        print(\"\\nTraining Examples:\")\n",
        "        for i, (src, trg) in enumerate(self.train_set[:5]):\n",
        "            print(f\"Example {i+1}:\")\n",
        "            print(f\"  SRC: {src}\")\n",
        "            print(f\"  TRG: {trg}\")\n",
        "\n",
        "        print(\"\\nValidation Examples:\")\n",
        "        for i, (src, trg) in enumerate(self.valid_set[:5]):\n",
        "            print(f\"Example {i+1}:\")\n",
        "            print(f\"  SRC: {src}\")\n",
        "            print(f\"  TRG: {trg}\")\n"
      ],
      "metadata": {
        "id": "ireKp2mmSfkb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizers and special symbols (Assume you have trained SentencePiece models)\n",
        "tokenizers = {\n",
        "    \"de\": sp_processor.tokenizers[\"de\"],  # SentencePiece tokenizer for German\n",
        "    \"en\": sp_processor.tokenizers[\"en\"]   # SentencePiece tokenizer for English\n",
        "}\n",
        "special_symbols = sp_processor.get_special_symbols_indexes()  # e.g., {\"BOS\": 1, \"EOS\": 2, \"PAD\": 3}\n",
        "\n",
        "# Initialize DataPreparation\n",
        "data_preparation = DataPreparation(\n",
        "    train_src_path=train_src_path,\n",
        "    train_trg_path=train_trg_path,\n",
        "    valid_src_path=valid_src_path,\n",
        "    valid_trg_path=valid_trg_path,\n",
        "    tokenizers=tokenizers,\n",
        "    special_symbols=special_symbols,\n",
        "    max_seq_len=50  # Maximum sequence length\n",
        ")\n",
        "\n",
        "# Print dataset information\n",
        "data_preparation.print_data_info()\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train_set = data_preparation.tokenize_dataset(data_preparation.train_set)\n",
        "tokenized_valid_set = data_preparation.tokenize_dataset(data_preparation.valid_set)\n",
        "\n",
        "# Example: Print the first tokenized train and valid example\n",
        "print(\"First tokenized training example:\")\n",
        "print(\"  SRC:\", tokenized_train_set[0][0])\n",
        "print(\"  TRG:\", tokenized_train_set[0][1])\n",
        "\n",
        "print(\"\\nFirst tokenized validation example:\")\n",
        "print(\"  SRC:\", tokenized_valid_set[0][0])\n",
        "print(\"  TRG:\", tokenized_valid_set[0][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHt48YodSzH5",
        "outputId": "a1539649-4a33-4d72-dc23-d267b9ef9ca8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "\n",
            "Training Examples:\n",
            "Example 1:\n",
            "  SRC: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
            "  TRG: Two young, White males are outside near many bushes.\n",
            "Example 2:\n",
            "  SRC: Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
            "  TRG: Several men in hard hats are operating a giant pulley system.\n",
            "Example 3:\n",
            "  SRC: Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
            "  TRG: A little girl climbing into a wooden playhouse.\n",
            "Example 4:\n",
            "  SRC: Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
            "  TRG: A man in a blue shirt is standing on a ladder cleaning a window.\n",
            "Example 5:\n",
            "  SRC: Zwei Männer stehen am Herd und bereiten Essen zu.\n",
            "  TRG: Two men are at the stove preparing food.\n",
            "\n",
            "Validation Examples:\n",
            "Example 1:\n",
            "  SRC: Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "  TRG: A group of men are loading cotton onto a truck\n",
            "Example 2:\n",
            "  SRC: Ein Mann schläft in einem grünen Raum auf einem Sofa.\n",
            "  TRG: A man sleeping in a green room on a couch.\n",
            "Example 3:\n",
            "  SRC: Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau.\n",
            "  TRG: A boy wearing headphones sits on a woman's shoulders.\n",
            "Example 4:\n",
            "  SRC: Zwei Männer bauen eine blaue Eisfischerhütte auf einem zugefrorenen See auf\n",
            "  TRG: Two men setting up a blue ice fishing hut on an iced over lake\n",
            "Example 5:\n",
            "  SRC: Ein Mann mit beginnender Glatze, der eine rote Rettungsweste trägt, sitzt in einem kleinen Boot.\n",
            "  TRG: A balding man wearing a red life jacket is sitting in a small boat.\n",
            "First tokenized training example:\n",
            "  SRC: tensor([   1,   25,   93,  137,   38,   99,   27,  107,    8,   18,  126,  280,\n",
            "          33, 4184,    4,    2])\n",
            "  TRG: tensor([   1,   22,   28,   18, 1317,  936,   20,   62,   89,  404, 1519,    5,\n",
            "           2])\n",
            "\n",
            "First tokenized validation example:\n",
            "  SRC: tensor([   1,   16,   45,   29,  306, 3382,  230, 9741,   12,   24, 1017,    2])\n",
            "  TRG: tensor([   1,    6,   42,   13,   39,   20, 1091,   16, 2719,  402,    9,   95,\n",
            "           4,  307,    2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def pad_sequence(batch, PAD):\n",
        "    src_seqs = [src for src, trg in batch]\n",
        "    trg_seqs = [trg for src, trg in batch]\n",
        "    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=PAD)\n",
        "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs, batch_first=True, padding_value=PAD)\n",
        "    return src_padded, trg_padded\n",
        "\n",
        "class Dataloaders:\n",
        "    def __init__(self, train_tokenized, valid_tokenized, batch_size, PAD):\n",
        "        self.train_dataset = TranslationDataset(train_tokenized)\n",
        "        self.valid_dataset = TranslationDataset(valid_tokenized)\n",
        "\n",
        "        self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size,\n",
        "                                                        shuffle=True, collate_fn=lambda x: pad_sequence(x, PAD))\n",
        "\n",
        "        self.valid_loader = torch.utils.data.DataLoader(self.valid_dataset, batch_size=batch_size,\n",
        "                                                        shuffle=True, collate_fn=lambda x: pad_sequence(x, PAD))"
      ],
      "metadata": {
        "id": "XC1GP5UKOEXY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "data_loaders = Dataloaders(tokenized_train_set, tokenized_valid_set, batch_size, PAD)"
      ],
      "metadata": {
        "id": "GXSwUE2tOEZj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer=nn.Linear(50,50)\n",
        "x=torch.rand(50)\n",
        "x.size()"
      ],
      "metadata": {
        "id": "6fx8qjfgTPHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_embed, dropout=0.0):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        #super().__init__()  python 3.x\n",
        "        assert d_embed % h == 0 # check the h number\n",
        "        self.d_k = d_embed//h\n",
        "        self.d_embed = d_embed    # 512\n",
        "        self.h = h  # 8\n",
        "        self.WQ = nn.Linear(d_embed, d_embed)\n",
        "        self.WK = nn.Linear(d_embed, d_embed)\n",
        "        self.WV = nn.Linear(d_embed, d_embed)\n",
        "        self.linear = nn.Linear(d_embed, d_embed)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x_query, x_key, x_value, mask=None):\n",
        "        nbatch = x_query.size(0) # get batch size\n",
        "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
        "        # attention scores has dimensions: nbatch * h * seq_len * seq_len\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
        "        # Mask out padding tokens\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask, float('-inf'))\n",
        "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
        "        p_atten = torch.nn.functional.softmax(scores, dim=-1) # attention filter\n",
        "        p_atten = self.dropout(p_atten)\n",
        "        # x dimensions: nbatch * h * seq_len * d_k\n",
        "        x = torch.matmul(p_atten, value)  # filtered values\n",
        "        # x now has dimensions:nbatch * seq_len * d_embed\n",
        "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
        "        return self.linear(x) # final linear layer"
      ],
      "metadata": {
        "id": "D-04_k50TPI_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dim, dropout):\n",
        "        super().__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(dim)  # (x-M)/std\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.drop(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "id": "J6ztnFpvT1aW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_embed = config.d_embed  # 512\n",
        "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) # Vocab Dictionary size , Embed size\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
        "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.norm = nn.LayerNorm(config.d_embed)\n",
        "\n",
        "    def forward(self, input, mask=None):\n",
        "        x = self.tok_embed(input) # Vectors\n",
        "        x_pos = self.pos_embed[:, :x.size(1), :]  # Vectors'\n",
        "        x = self.dropout(x + x_pos) # update vectors with position information\n",
        "        for layer in self.encoder_blocks:\n",
        "            x = layer(x, mask) # (50,512)\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
        "    def __init__(self, config):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(config.d_embed, config.d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.d_ff, config.d_embed)\n",
        "        )\n",
        "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
        "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # self-attention\n",
        "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
        "        # position-wise fully connected feed-forward layer\n",
        "        return self.residual2(x, self.feed_forward)\n"
      ],
      "metadata": {
        "id": "RXrgZpUhT1a3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_embed = config.d_embed\n",
        "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
        "        self.norm = nn.LayerNorm(config.d_embed)\n",
        "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
        "\n",
        "\n",
        "    def future_mask(self, seq_len):\n",
        "        '''mask out tokens at future positions'''\n",
        "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
        "        return mask.view(1, 1, seq_len, seq_len)\n",
        "\n",
        "    def forward(self, memory, src_mask, trg, trg_pad_mask):\n",
        "        seq_len = trg.size(1)\n",
        "        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n",
        "        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n",
        "        x = self.dropout(x)\n",
        "        for layer in self.decoder_blocks:\n",
        "            x = layer(memory, src_mask, x, trg_mask)\n",
        "        x = self.norm(x)\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    ''' DecoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n",
        "        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(config.d_embed, config.d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.d_ff, config.d_embed)\n",
        "        )\n",
        "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout)\n",
        "                                       for _ in range(3)])\n",
        "\n",
        "    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n",
        "        x = memory  # K , V\n",
        "        y = decoder_layer_input # target /y \"he\"\n",
        "        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask)) #masked multi head attention\n",
        "        # keys and values are from the encoder output\n",
        "        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n",
        "        return self.residuals[2](y, self.feed_forward)\n"
      ],
      "metadata": {
        "id": "p1wSJoXtT1cH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, src_mask, trg, trg_pad_mask):\n",
        "        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"
      ],
      "metadata": {
        "id": "QkhgSf2CT1dw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model configuration and creation\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    encoder_vocab_size: int\n",
        "    decoder_vocab_size: int\n",
        "    d_embed: int\n",
        "    d_ff: int\n",
        "    h: int\n",
        "    N_encoder: int\n",
        "    N_decoder: int\n",
        "    max_seq_len: int\n",
        "    dropout: float\n",
        "\n",
        "def make_model(config):\n",
        "    model = Transformer(Encoder(config), Decoder(config)).to(DEVICE)\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model\n",
        "\n",
        "def make_batch_input(x, y):\n",
        "        src = x.to(DEVICE)\n",
        "        trg_in = y[:, :-1].to(DEVICE)\n",
        "        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n",
        "        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n",
        "        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
        "        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask\n",
        "\n",
        "# Placeholder for train and evaluate functions\n",
        "def train_epoch(model, dataloaders):\n",
        "    model.train()\n",
        "    grad_norm_clip = 1.0\n",
        "    losses = []\n",
        "    pbar = tqdm(enumerate(dataloaders.train_loader), total=len(dataloaders.train_loader))\n",
        "    for idx, (x, y) in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x, y)\n",
        "        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
        "        pred = pred.view(-1, pred.size(-1))\n",
        "        loss = loss_fn(pred, trg_out).to(DEVICE)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        losses.append(loss.item())\n",
        "        if idx > 0 and idx % 50 == 0:\n",
        "            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n",
        "    return np.mean(losses)\n",
        "\n",
        "def train(model, dataloaders, epochs):\n",
        "    global early_stop_count\n",
        "    best_valid_loss = float('inf')\n",
        "    train_size = len(dataloaders.train_loader) * batch_size\n",
        "    for ep in range(epochs):\n",
        "        train_loss = train_epoch(model, dataloaders)\n",
        "        valid_loss = validate(model, dataloaders.valid_loader)\n",
        "\n",
        "        print(f'ep: {ep}: train_loss={train_loss:.5f}, valid_loss={valid_loss:.5f}')\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "        else:\n",
        "            if scheduler.last_epoch > 2 * warmup_steps:\n",
        "                early_stop_count -= 1\n",
        "                if early_stop_count <= 0:\n",
        "                    return train_loss, valid_loss\n",
        "    return train_loss, valid_loss\n",
        "\n",
        "def validate(model, dataloder):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(dataloder):\n",
        "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x, y)\n",
        "            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
        "            pred = pred.view(-1, pred.size(-1))\n",
        "            losses.append(loss_fn(pred, trg_out).item())\n",
        "    return np.mean(losses)\n",
        "\n",
        "def translate(model, x, detokenizers):\n",
        "    'translate source sentences into the target language, without looking at the answer'\n",
        "    with torch.no_grad():\n",
        "        dB = x.size(0)\n",
        "        y = torch.tensor([[BOS]*dB]).view(dB, 1).to(DEVICE)\n",
        "        x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n",
        "        memory = model.encoder(x, x_pad_mask)\n",
        "        for i in range(max_seq_len):\n",
        "            y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n",
        "            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
        "            last_output = logits.argmax(-1)[:, -1]\n",
        "            last_output = last_output.view(dB, 1)\n",
        "            y = torch.cat((y, last_output), 1).to(DEVICE)\n",
        "    return y\n",
        "\n",
        "def remove_pad(sent):\n",
        "    '''truncate the sentence if BOS is in it,\n",
        "     otherwise simply remove the padding tokens at the end'''\n",
        "    if sent.count(EOS)>0:\n",
        "        sent = sent[0:sent.index(EOS)+1]\n",
        "    while sent and sent[-1] == PAD:\n",
        "        sent = sent[:-1]\n",
        "    return sent\n",
        "\n",
        "def decode_sentence(detokenizer, sentence_ids):\n",
        "    'convert a tokenized sentence (a list of numbers) to a literal string'\n",
        "    if not isinstance(sentence_ids, list):\n",
        "        sentence_ids = sentence_ids.tolist()\n",
        "    sentence_ids = remove_pad(sentence_ids)\n",
        "    return detokenizer(sentence_ids).replace(\"<bos>\", \"\")\\\n",
        "           .replace(\"<eos>\", \"\").strip().replace(\" .\", \".\")\n",
        "\n",
        "def evaluate(model, dataloader, detokenizers, num_batch=None):\n",
        "    'evaluate the model, and compute the BLEU score'\n",
        "    model.eval()\n",
        "    refs, cans, bleus = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(dataloader):\n",
        "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x, y)\n",
        "            translation = translate(model, src, detokenizers)\n",
        "            trg_out = trg_out.view(x.size(0), -1)\n",
        "            refs = refs + [decode_sentence(detokenizers[TRG], trg_out[i]) for i in range(len(src))]\n",
        "            cans = cans + [decode_sentence(detokenizers[TRG], translation[i]) for i in range(len(src))]\n",
        "            if num_batch and idx>=num_batch:\n",
        "                break\n",
        "        print(min([len(x) for x in refs]))\n",
        "        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n",
        "        # print some examples\n",
        "        for i in range(3):\n",
        "            print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n",
        "            print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n",
        "            print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n",
        "        return np.mean(bleus)"
      ],
      "metadata": {
        "id": "jnI_IysMT1fh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detokenizers = {\n",
        "    SRC: sp_processor.tokenizers[SRC].decode_ids,  # German detokenizer\n",
        "    TRG: sp_processor.tokenizers[TRG].decode_ids  # English detokenizer\n",
        "}\n",
        "\n",
        "config = ModelConfig(\n",
        "    encoder_vocab_size=vocab_sizes[SRC],\n",
        "    decoder_vocab_size=vocab_sizes[TRG],\n",
        "    d_embed=512,\n",
        "    d_ff=512,\n",
        "    h=8,\n",
        "    N_encoder=6,\n",
        "    N_decoder=6,\n",
        "    max_seq_len=max_seq_len,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "train_size = len(data_loaders.train_loader) * batch_size\n",
        "\n",
        "# Create model\n",
        "model = make_model(config)\n",
        "model_size = sum([p.numel() for p in model.parameters()])\n",
        "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
        "\n",
        "# Learning rate scheduler setup\n",
        "warmup_steps = 3 * len(data_loaders.train_loader)\n",
        "lr_fn = lambda step: config.d_embed ** -0.5 * min([(step + 1) ** -0.5, (step + 1) * warmup_steps ** -1.5])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
        "\n",
        "# Training parameters\n",
        "early_stop_count = 10\n",
        "\n",
        "# Train the model\n",
        "train_loss, valid_loss = train(model, data_loaders, epochs=50)\n",
        "\n",
        "print(\"train set examples:\")\n",
        "train_bleu = evaluate(model, data_loaders.train_loader, detokenizers, 20)\n",
        "print(\"validation set examples:\")\n",
        "valid_bleu = evaluate(model, data_loaders.valid_loader, detokenizers)"
      ],
      "metadata": {
        "id": "3x2U6A93T1hV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232d4b6e-3555-43e1-edc8-54b26dda9ea6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_size: 38823944, train_set_size: 29056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=3.796, lr=0.00025: 100%|██████████| 227/227 [01:04<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 0: train_loss=5.51753, valid_loss=3.73809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=2.746, lr=0.00053: 100%|██████████| 227/227 [01:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 1: train_loss=3.15520, valid_loss=2.63824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=2.201, lr=0.00082: 100%|██████████| 227/227 [01:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 2: train_loss=2.28024, valid_loss=2.17410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.812, lr=0.00074: 100%|██████████| 227/227 [01:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 3: train_loss=1.81368, valid_loss=1.94048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.450, lr=0.00066: 100%|██████████| 227/227 [01:04<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 4: train_loss=1.47925, valid_loss=1.85235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.311, lr=0.00060: 100%|██████████| 227/227 [01:04<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 5: train_loss=1.24379, valid_loss=1.80811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=1.132, lr=0.00056: 100%|██████████| 227/227 [01:04<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 6: train_loss=1.06370, valid_loss=1.81389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.970, lr=0.00052: 100%|██████████| 227/227 [01:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 7: train_loss=0.91957, valid_loss=1.82270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.806, lr=0.00049: 100%|██████████| 227/227 [01:03<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 8: train_loss=0.80130, valid_loss=1.85435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.757, lr=0.00047: 100%|██████████| 227/227 [01:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 9: train_loss=0.69876, valid_loss=1.90574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.631, lr=0.00044: 100%|██████████| 227/227 [01:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 10: train_loss=0.61593, valid_loss=1.94202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.584, lr=0.00043: 100%|██████████| 227/227 [01:03<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 11: train_loss=0.54530, valid_loss=1.98453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.559, lr=0.00041: 100%|██████████| 227/227 [01:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 12: train_loss=0.48279, valid_loss=2.04879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.493, lr=0.00039: 100%|██████████| 227/227 [01:04<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 13: train_loss=0.43000, valid_loss=2.09650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.460, lr=0.00038: 100%|██████████| 227/227 [01:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 14: train_loss=0.38626, valid_loss=2.15867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss=0.376, lr=0.00037: 100%|██████████| 227/227 [01:04<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep: 15: train_loss=0.34530, valid_loss=2.19668\n",
            "train set examples:\n",
            "19\n",
            "src:  Ein Mann, der einen grünen Jeep fährt, fährt über große Steine.\n",
            "trg:  A man driving a green jeep is crossing over large rocks.\n",
            "pred: A man driving a green jeep is driving over large rocks.\n",
            "src:  Eine Frau in einem blauen Pullover hält ein großes Stück braunes Papier.\n",
            "trg:  Woman wearing a blue sweater while holding a large piece of brown paper material.\n",
            "pred: A woman in a blue sweater holds a large piece of brown paper.\n",
            "src:  Ein Paar steht da und blickt auf das Meer.\n",
            "trg:  A couple stand and looks at the ocean.\n",
            "pred: A couple stands and looks at the ocean.\n",
            "validation set examples:\n",
            "20\n",
            "src:  Ein schwarzweißer Hund schwimmt im klaren Wasser.\n",
            "trg:  A black and white dog swimming in clear water.\n",
            "pred: A black and white dog is swimming in the clear water.\n",
            "src:  Eine Gruppe junger asiatischer Männer läuft bei einem Marathon.\n",
            "trg:  A group of young Asian men walking in a marathon.\n",
            "pred: A group of young Asian men are walking in a marathon.\n",
            "src:  Ein Mann rollt einen runden Tisch über den Boden.\n",
            "trg:  A man is rolling a circular table across the floor.\n",
            "pred: A man is rolling a roundcross the ground.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_this_sentence(text: str, model, tokenizers, detokenizers):\n",
        "    'translate the source sentence in string formate into target language'\n",
        "    input = torch.tensor([[BOS] + tokenizers[SRC](text) + [EOS]]).to(DEVICE)\n",
        "    output = translate(model, input, detokenizers)\n",
        "    return decode_sentence(detokenizers[TRG], output[0])"
      ],
      "metadata": {
        "id": "UcZotpV6ULEu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_this_sentence(sentence, model, tokenizers, detokenizers):\n",
        "    \"\"\"\n",
        "    Translates a given sentence using the trained model.\n",
        "\n",
        "    Args:\n",
        "    - sentence (str): Input sentence in the source language.\n",
        "    - model (nn.Module): Trained Transformer model.\n",
        "    - tokenizers (dict): Tokenizers for source and target languages.\n",
        "    - detokenizers (dict): Detokenizers for source and target languages.\n",
        "\n",
        "    Returns:\n",
        "    - str: Translated sentence in the target language.\n",
        "    \"\"\"\n",
        "    # Tokenize the input sentence\n",
        "    src_tokens = tokenizers[\"de\"].encode_as_ids(sentence)  # Tokenize German sentence\n",
        "    src_tensor = torch.tensor([src_tokens], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    # Translate the sentence\n",
        "    translated_tensor = translate(model, src_tensor, detokenizers)  # Get translated token IDs\n",
        "\n",
        "    # Decode the translated tokens into a sentence\n",
        "    translated_sentence = detokenizers[\"en\"](translated_tensor[0].tolist())  # Use correct detokenizer\n",
        "    return translated_sentence\n"
      ],
      "metadata": {
        "id": "Zpwj2f89ULFP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_sentence = translate_this_sentence(\n",
        "    \"Eine Gruppe von Menschen steht vor einem Iglu.\",  # German input\n",
        "    model,  # Your trained Transformer model\n",
        "    tokenizers,  # Tokenizers dictionary\n",
        "    detokenizers  # Detokenizers dictionary\n",
        ")\n",
        "print(translated_sentence)\n",
        "\n"
      ],
      "metadata": {
        "id": "KvT5qUWx4Oyd",
        "outputId": "1e2b800b-b985-4fbf-ad41-ed8d109d8ef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group of people standing in front of an igloo.......... air..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'transformer_model.pth')"
      ],
      "metadata": {
        "id": "9ZYFVYOqUPjP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSwo7TXf4OIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}